{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_CAM_RPi_ANN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOx6mc/oPgT4o6f9v/XF/Vy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jehee-lee/jjtech/blob/main/mnist_CAM_RPi_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37g2YnHxt04D"
      },
      "source": [
        "모델 생성, 모델 매개변수 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lbHsQ_xt0vK"
      },
      "source": [
        "import torch\r\n",
        "from torch import nn, optim\r\n",
        "import torch.nn.functional as F\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "class Net(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self):\r\n",
        "        super(Net, self).__init__()\r\n",
        "        self.l1 = nn.Linear(784, 520)\r\n",
        "        self.l2 = nn.Linear(520, 320)\r\n",
        "        self.l3 = nn.Linear(320, 240)\r\n",
        "        self.l4 = nn.Linear(240, 120)\r\n",
        "        self.l5 = nn.Linear(120, 10)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = x.view(-1, 784)  # Flatten the data (n, 1, 28, 28)-> (n, 784)\r\n",
        "        x = F.relu(self.l1(x))\r\n",
        "        x = F.relu(self.l2(x))\r\n",
        "        x = F.relu(self.l3(x))\r\n",
        "        x = F.relu(self.l4(x))\r\n",
        "        return self.l5(x)\r\n",
        "\r\n",
        "device = torch.device('cpu')\r\n",
        "model = Net()\r\n",
        "PATH = './model/'\r\n",
        "model.load_state_dict(torch.load(PATH + 'model_for_RO_ANN.pt', map_location=device))\r\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntlliyhfuJIT"
      },
      "source": [
        "하드웨어 핀 설정 (GPIO)\r\n",
        "\r\n",
        "및 비디오 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9NS6FmztrlO"
      },
      "source": [
        "import RPi.GPIO as GPIO\r\n",
        "import cv2\r\n",
        "from time import sleep as sl\r\n",
        "\r\n",
        "led = 21\r\n",
        "button = 16\r\n",
        "GPIO.setmode(GPIO.BCM)\r\n",
        "\r\n",
        "GPIO.setup(led,GPIO.OUT)\r\n",
        "GPIO.setup(button,GPIO.IN,pull_up_down=GPIO.PUD_UP)\r\n",
        "cap = cv2.VideoCapture(0)\r\n",
        "\r\n",
        "frame_size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\r\n",
        "         int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\r\n",
        "\r\n",
        "print(frame_size)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FTaXXnXuaRF"
      },
      "source": [
        "콜백함수 지정 및 인터럽트 실행문 선언\r\n",
        "\r\n",
        "콜백함수는 버튼이 눌려지면 (풀업저항이 RISING될 때) 실행됨\r\n",
        "\r\n",
        "콜백함수 구성)\r\n",
        "*   led High\r\n",
        "*   현재 이미지 저장\r\n",
        "*   저장된 이미지 불러오기\r\n",
        "*   led Low\r\n",
        "*   이미지 전처리(이진화, 리사이징)\r\n",
        "*   이미지 예측 및 이미지 출력\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdOr0J5kuXVI"
      },
      "source": [
        "def call_back_for_capture(channel):\r\n",
        "    print(\"button pressed\")\r\n",
        "    GPIO.output(led,GPIO.HIGH)\r\n",
        "    cv2.imwrite('./data/mnist.jpg',frame1)\r\n",
        "    sl(1)\r\n",
        "    img = cv2.imread('./data/mnist.jpg', cv2.IMREAD_GRAYSCALE)\r\n",
        "    GPIO.output(led,GPIO.LOW)\r\n",
        "    _, img1 = cv2.threshold(img,160, 255, cv2.THRESH_BINARY_INV) #threshold값은 주변 환경에 따라 수시로 수정해줄 것\r\n",
        "    img2 = cv2.resize(img1, (28,28), interpolation = cv2.INTER_AREA)\r\n",
        "    img3=torch.from_numpy(img2)\r\n",
        "    result = img3.view(-1,28*28).float().to(device)\r\n",
        "    single_prediction = model(result)\r\n",
        "    print('Prediction:', torch.argmax(single_prediction,1).item())\r\n",
        "    plt.imshow(img3.view(28,28),cmap='Greys')\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "GPIO.add_event_detect(button, GPIO.RISING,\r\n",
        "                      callback=call_back_for_capture)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocNo4dwtumpw"
      },
      "source": [
        "스트림 실행\r\n",
        "(esc를 누르면 종료)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqLxaAgNuZbR"
      },
      "source": [
        "while(cap.isOpened()):\r\n",
        "    ret, frame = cap.read()\r\n",
        "    frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\r\n",
        "    frame = frame[500:1500,800:1800]\r\n",
        "    frame1 = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\r\n",
        "    if (ret):\r\n",
        "        frame2 = cv2.resize(frame1, dsize=(640, 480), interpolation=cv2.INTER_AREA)\r\n",
        "        cv2.imshow('stream',frame2)\r\n",
        "        cv2.moveWindow('stream',200,100)\r\n",
        "        k = cv2.waitKey(1) & 0xFF\r\n",
        "        if(k== 27):\r\n",
        "            break;\r\n",
        "cap.release()\r\n",
        "cv2.destroyAllWindows()\r\n",
        "GPIO.cleanup"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}