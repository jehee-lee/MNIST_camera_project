{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_CAM_RPi_CNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOaTCS9WsPHYLQ87hmF98Hn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jehee-lee/jjtech/blob/main/mnist_CAM_RPi_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Zuk1TUpwrYb"
      },
      "source": [
        "모델 생성, 매개변수 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ0zwIgRwv_B"
      },
      "source": [
        "import torch\r\n",
        "from torch import nn, optim\r\n",
        "import torch.nn.functional as F\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "class Net(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self):\r\n",
        "        super(Net, self).__init__()\r\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\r\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\r\n",
        "        self.mp = nn.MaxPool2d(2)\r\n",
        "        self.fc = nn.Linear(320, 10)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        in_size = x.size(0)\r\n",
        "        x = F.relu(self.mp(self.conv1(x)))\r\n",
        "        x = F.relu(self.mp(self.conv2(x)))\r\n",
        "        x = x.view(in_size, -1)  # flatten the tensor\r\n",
        "        x = self.fc(x)\r\n",
        "        return F.log_softmax(x)\r\n",
        "  \r\n",
        "device = torch.device('cpu')\r\n",
        "model = Net()\r\n",
        "PATH = './model/'\r\n",
        "model.load_state_dict(torch.load(PATH + 'model_for_RO_CNN.pt', map_location=device))\r\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrTbITYxw0oQ"
      },
      "source": [
        "하드웨어 핀 설정 (GPIO) 및 비디오 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uBVkHNjwcpX"
      },
      "source": [
        "import RPi.GPIO as GPIO\r\n",
        "import cv2\r\n",
        "from time import sleep as sl\r\n",
        "\r\n",
        "led = 21\r\n",
        "button = 16\r\n",
        "GPIO.setmode(GPIO.BCM)\r\n",
        "\r\n",
        "GPIO.setup(led,GPIO.OUT)\r\n",
        "GPIO.setup(button,GPIO.IN,pull_up_down=GPIO.PUD_UP)\r\n",
        "cap = cv2.VideoCapture(0)\r\n",
        "\r\n",
        "frame_size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\r\n",
        "         int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7i9IIkRw8Vr"
      },
      "source": [
        "콜백함수 지정 및 인터럽트 실행문 선언\r\n",
        "\r\n",
        "ANN과 달리 모델에 들어가는 input의 형태가 4 텐서이기 때문에\r\n",
        "\r\n",
        "이미지를 [1, 1, 28, 28]텐서형으로 변경 ( => [5,1,10,10] conv신경망으로 읽힘 )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FuZCu2ow_I4"
      },
      "source": [
        "print(frame_size)\r\n",
        "\r\n",
        "def call_back_for_capture(channel):\r\n",
        "    print(\"button pressed\")\r\n",
        "    GPIO.output(led,GPIO.HIGH)\r\n",
        "    cv2.imwrite('./data/mnist.jpg',frame1)\r\n",
        "    sl(1)\r\n",
        "    img = cv2.imread('./data/mnist.jpg', cv2.IMREAD_GRAYSCALE)\r\n",
        "    GPIO.output(led,GPIO.LOW)\r\n",
        "    _, img1 = cv2.threshold(img,160, 255, cv2.THRESH_BINARY_INV)\r\n",
        "    img2 = cv2.resize(img1, (28,28), interpolation = cv2.INTER_AREA)\r\n",
        "    img3=torch.from_numpy(img2)\r\n",
        "    result = img3.view(1,1,28,28).float().to(device) #코드 수정\r\n",
        "    single_prediction = model(result)\r\n",
        "    print('Prediction:', torch.argmax(single_prediction,1).item())\r\n",
        "    plt.imshow(img3.view(28,28),cmap='Greys')\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "GPIO.add_event_detect(button, GPIO.RISING,\r\n",
        "                      callback=call_back_for_capture)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GnbrWEmxEBf"
      },
      "source": [
        "스트림 영상 출력\r\n",
        "(esc를 누르면 종료)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ObpDup9xD1W"
      },
      "source": [
        "\r\n",
        "while(cap.isOpened()):\r\n",
        "    ret, frame = cap.read()\r\n",
        "    frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\r\n",
        "    frame = frame[500:1500,800:1800]\r\n",
        "    frame1 = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\r\n",
        "    if (ret):\r\n",
        "        frame2 = cv2.resize(frame1, dsize=(640, 480), interpolation=cv2.INTER_AREA)\r\n",
        "        cv2.imshow('stream',frame2)\r\n",
        "        cv2.moveWindow('stream',200,100)\r\n",
        "        k = cv2.waitKey(1) & 0xFF\r\n",
        "        if(k== 27):\r\n",
        "            break;\r\n",
        "cap.release()\r\n",
        "cv2.destroyAllWindows()\r\n",
        "GPIO.cleanup"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}